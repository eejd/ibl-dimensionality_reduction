{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction for IBL Neuropixel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to demonstrate the dimensionality reduction code and analysis approaches for IBL neural data. The code is prototype level code from the IBL Code Camp hackathon. In this notebook you will need to set and load data and then you can use the dimensionality reduction functions provided in the dim_reduce.py module. This module needs to be on your python path or in the kernel's execution directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will append any local directories needed for packages and\n",
    "# development modules not installed in the conda 'ibllib' environment\n",
    "\n",
    "# core python\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# sys.path.append(r'C:\\Leenoy\\Postdoc 1st year\\IBL\\Code_camp_September_2019\\data_code_camp\\dim_red_WG\\umap-master')\n",
    "# sys.path.append('/Users/dep/Workspaces/Rodent/IBL/ibllib')\n",
    "sys.path.append('/Users/dep/Workspaces/Rodent/IBL/code_camp/ibl-dimensionality_reduction/')\n",
    "\n",
    "# scientific libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import Isomap, MDS, TSNE, LocallyLinearEmbedding\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# import umap\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ibl\n",
    "import alf.io  \n",
    "from brainbox.processing import bincount2D\n",
    "import ibllib.plots as iblplt\n",
    "import dim_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data location and loading\n",
    "Note that we will be converting the data structrures used in the following weeks,\n",
    "so this code currently uses base alf objects and a dictionaries, but it will be converted\n",
    "to use Bunch and also Panda Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-49ce2ecc4607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# define the path to the sessions we downloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# main_path = Path(r'C:\\Leenoy\\Postdoc 1st year\\IBL\\Code_camp_September_2019\\data_code_camp')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/dep/Workspaces/Rodent/IBL/code_camp/data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m SES = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmain_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ZM_1735/2019-08-01/001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# RSC --> CA1 --> midbrain, good behavior, bad recroding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# define the path to the sessions we downloaded \n",
    "# main_path = Path(r'C:\\Leenoy\\Postdoc 1st year\\IBL\\Code_camp_September_2019\\data_code_camp')\n",
    "main_path = Path('/Users/alex/Downloads/')\n",
    "SES = {\n",
    "    'A': main_path.joinpath(Path('ZM_1735/2019-08-01/001')), # RSC --> CA1 --> midbrain, good behavior, bad recroding\n",
    "    'B': main_path.joinpath(Path('ibl_witten_04_002/2019-08-04/002')), # visual cortex, good behavior, noisy recording\n",
    "    'C': main_path.joinpath(Path('ZM_1736/2019-08-09/004')),  # left probe, bad behavior, good recording\n",
    "    'D': main_path.joinpath(Path('ibl_witten_04_001/2018-08-11/001')), # motor cortex, bad beahvior, good recording\n",
    "    'E': main_path.joinpath(Path('KS005/2019-08-29/001')), # activity in in red nucleaus, bad recording (serious lick artifacts and some units saturated) \n",
    "#    'F': main_path.joinpath(Path('KS005/2019-08-30/001')), # too large, didnt download for now\n",
    "}\n",
    "\n",
    "# select a session from the bunch\n",
    "sid = 'A'\n",
    "ses_path = Path(SES[sid])\n",
    "\n",
    "# read in the alf objects\n",
    "alf_path = ses_path / 'alf'\n",
    "spikes = alf.io.load_object(alf_path, 'spikes')  #can be addressed as spikes['time'] or spikes.time\n",
    "clusters = alf.io.load_object(alf_path, 'clusters')\n",
    "channels = alf.io.load_object(alf_path, 'channels')\n",
    "trials = alf.io.load_object(alf_path, '_ibl_trials')\n",
    "wheel = alf.io.load_object(alf_path, '_ibl_wheel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions from dim_reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for analysis\n",
    "T_BIN is the size in seconds of the bins applied to the neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_BIN = 0.1\n",
    "TRIALS_TO_PLOT = np.arange(40,90) # note that we use the real trial numbers\n",
    "PROJECTED_DIMENSIONS = 3\n",
    "BEHAVIORAL_VARIABLE = 'wheel_velocity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_data = dim_reduce.bin_types(spikes, trials, wheel, T_BIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data, variable_data = dim_reduce.get_trials(binned_data, BEHAVIORAL_VARIABLE, TRIALS_TO_PLOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Components Analysis\n",
    "The following code cell runs PCA using the wheel velocity for color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_projected_data = PCA(n_components=PROJECTED_DIMENSIONS, svd_solver='full').fit_transform(neural_data)\n",
    "ax = dim_reduce.color_3D_projection(pca_projected_data, variable_data)\n",
    "ax.set_title(\"PCA Guido's RSC --> CA1 --> midbrain recording vs %s\" % BEHAVIORAL_VARIABLE, fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demixed Principle Components Analysis\n",
    "The following code cell runs demixed PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy in dPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_projected_data = FactorAnalysis(n_components=PROJECTED_DIMENSIONS).fit_transform(neural_data)\n",
    "dim_reduce.color_3D_projection(fa_projected_data, variable_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
