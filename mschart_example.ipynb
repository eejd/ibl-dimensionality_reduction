{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from oneibl.one import ONE\n",
    "from brainbox.processing import bincount2D\n",
    "import alf.io as ioalf\n",
    "import ibllib.plots as iblplt\n",
    "from sklearn import manifold\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def bin_types(spikes, trials, wheel):\n",
    "\n",
    "    T_BIN = 0.2  # [sec]\n",
    "\n",
    "    # TO GET MEAN: bincount2D(..., weight=positions) / bincount2D(..., weight=None)\n",
    "\n",
    "    reward_times = trials['feedback_times'][trials['feedbackType'] == 1]\n",
    "    trial_start_times = trials['intervals'][:, 0]\n",
    "    # trial_end_times = trials['intervals'][:, 1] #not working as there are\n",
    "    # nans\n",
    "    # compute raster map as a function of cluster number\n",
    "    R1, times1, _ = bincount2D(\n",
    "        spikes['times'], spikes['clusters'], T_BIN, weights=spikes['amps'])\n",
    "    R2, times2, _ = bincount2D(\n",
    "        reward_times, np.array(\n",
    "            [0] * len(reward_times)), T_BIN)\n",
    "    R3, times3, _ = bincount2D(\n",
    "        trial_start_times, np.array(\n",
    "            [0] * len(trial_start_times)), T_BIN)\n",
    "    R4, times4, _ = bincount2D(wheel['times'], np.array(\n",
    "        [0] * len(wheel['times'])), T_BIN, weights=wheel['position'])\n",
    "    R5, times5, _ = bincount2D(wheel['times'], np.array(\n",
    "        [0] * len(wheel['times'])), T_BIN, weights=wheel['velocity'])\n",
    "    #R6, times6, _ = bincount2D(trial_end_times, np.array([0]*len(trial_end_times)), T_BIN)\n",
    "    start = max([x for x in [times1[0], times2[0], times3[0], times4[0], times5[0]]])\n",
    "    stop = min([x for x in [times1[-1], times2[-1],\n",
    "                            times3[-1], times4[-1], times5[-1]]])\n",
    "    time_points = np.linspace(start, stop, int((stop - start) / T_BIN))\n",
    "    binned_data = {}\n",
    "    binned_data['wheel_position'] = np.interp(\n",
    "        time_points, wheel['times'], wheel['position'])\n",
    "    binned_data['wheel_velocity'] = np.interp(\n",
    "        time_points, wheel['times'], wheel['velocity'])\n",
    "    binned_data['summed_spike_amps'] = R1[:, find_nearest(\n",
    "        times1, start):find_nearest(times1, stop)]\n",
    "    binned_data['reward_event'] = R2[0, find_nearest(\n",
    "        times2, start):find_nearest(times2, stop)]\n",
    "    binned_data['trial_start_event'] = R3[0, find_nearest(\n",
    "        times3, start):find_nearest(times3, stop)]\n",
    "    # binned_data['trial_end_event']=R6[0,find_nearest(times6,start):find_nearest(times6,stop)]\n",
    "    # np.vstack([R1,R2,R3,R4])\n",
    "    return binned_data\n",
    "\n",
    "def color_attractor(binned_data, bounds):\n",
    "\n",
    "    # obs_limit=1000 #else it's too slow  \n",
    "    low, high = bounds\n",
    "\n",
    "    X = binned_data['summed_spike_amps'][:, low:high].T\n",
    "    Y = manifold.Isomap(n_components=3).fit_transform(X)\n",
    "\n",
    "    x, y, z = np.split(Y, 3, axis=1)\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    p = ax.scatter(x, y, z, s=20, alpha=0.25, c=abs(\n",
    "        binned_data['wheel_velocity'][low:high]), cmap='binary')\n",
    "    fig.colorbar(p)\n",
    "    plt.title(\"Guido's motor cortex --> thalamus recording vs wheel speed\")\n",
    "    # plt.scatter(Y.T[0,:],Y.T[1,:],s=1,alpha=0.9,c=D_trial['wheel_velocity'][trial])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the data from flatiron and the current folder\n",
    "#one = ONE()\n",
    "#eid = one.search(subject='ZM_1736', date='2019-08-09', number=4)\n",
    "#D = one.load(eid[0], clobber=False, download_only=True)\n",
    "#session_path = Path(D.local_path[0]).parent\n",
    "session_path = Path('~/Workspaces/Rodent/IBL/code_camp/data/ZM_1735/2019-08-01/001/alf')\n",
    "\n",
    "# load objects\n",
    "spikes = ioalf.load_object(session_path, 'spikes')\n",
    "trials = ioalf.load_object(session_path, '_ibl_trials')\n",
    "wheel = ioalf.load_object(session_path, '_ibl_wheel')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_types(spikes, trials, wheel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ibllib] *",
   "language": "python",
   "name": "conda-env-ibllib-py"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
